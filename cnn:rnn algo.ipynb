import os
import cv2
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torch.nn as nn
import torch.optim as optim

# Constants
NUM_FRAMES = 30  # Number of frames to sample from each video

# Step 1: Custom Dataset Class for Video Files
class VideoDataset(Dataset):
    def __init__(self, video_dir, labels, transform=None):
        self.video_dir = video_dir
        self.labels = labels  # A list of labels corresponding to the videos
        all_files = os.listdir(video_dir)
        print("All Files in Directory:", all_files)  # Debug print

        # Update file types as necessary
        self.video_files = [f for f in all_files if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]
        print("Video Files Found:", self.video_files)  # Debug print

        if len(self.video_files) == 0:
            raise ValueError("No video files found in the specified directory.")

        self.transform = transform

    def __len__(self):
        return len(self.video_files)

    def __getitem__(self, idx):
        video_path = os.path.join(self.video_dir, self.video_files[idx])
        video = self.load_video(video_path)

        # Sample frames
        if len(video) >= NUM_FRAMES:
            frame_indices = np.linspace(0, len(video) - 1, NUM_FRAMES).astype(int)
            video = video[frame_indices]  # Sample NUM_FRAMES
        else:
            # If video has fewer frames, pad with the last frame
            pad_width = NUM_FRAMES - len(video)
            last_frame = video[-1]
            video = np.pad(video, ((0, pad_width), (0, 0), (0, 0)), mode='edge')

        # Apply transformation to each frame
        if self.transform:
            video = [self.transform(frame) for frame in video]

        # Stack frames into a tensor
        video_tensor = torch.stack(video)  # Shape: [num_frames, channels, height, width]
        
        # Reshape to [channels, num_frames, height, width]
        video_tensor = video_tensor.permute(1, 0, 2, 3)  # Now: [channels, num_frames, height, width]

        # Get the label for the current video
        label = self.labels[idx]  # Get corresponding label

        return video_tensor, label  # Return both the video tensor and the label

    def load_video(self, video_path):
        cap = cv2.VideoCapture(video_path)
        frames = []

        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame)

        cap.release()
        return np.array(frames)

# Define your transformations
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Step 2: Load your dataset
# Define your labels for the training dataset
# This should be a list where each label corresponds to the video file in the same order
# Adjust the labels as needed
train_labels = [0] * len(os.listdir('/Users/fabinbhuiyan/Downloads/datasets/deepfakes/train/real_videos'))  # 0 for real
test_labels = [1] * len(os.listdir('/Users/fabinbhuiyan/Downloads/datasets/deepfakes/train/fake_videos'))  # 1 for fake

train_dataset = VideoDataset(video_dir='/Users/fabinbhuiyan/Downloads/datasets/deepfakes/train/real_videos', labels=train_labels, transform=transform)
test_dataset = VideoDataset(video_dir='/Users/fabinbhuiyan/Downloads/datasets/deepfakes/train/fake_videos', labels=test_labels, transform=transform)

# Create DataLoader objects to manage batches of data
train_loader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=False)

# Step 3: Define a Simple CNN model
class SimpleCNN(nn.Module):
    def __init__(self, num_classes):
        super(SimpleCNN, self).__init__()
        self.base_model = nn.Sequential(
            nn.Conv3d(3, 16, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(16),
            nn.ReLU(),
            nn.MaxPool3d(kernel_size=2, stride=2),
            nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(32),
            nn.ReLU(),
            nn.MaxPool3d(kernel_size=2, stride=2),
            nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(),
            nn.MaxPool3d(kernel_size=2, stride=2),
            nn.Dropout(0.5)
        )
        self.fc = nn.Linear(64 * (NUM_FRAMES // 8) * (224 // 8) * (224 // 8), num_classes)

    def forward(self, x):
        x = self.base_model(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x


# Step 4: Train the Models
def train_model(model, train_loader, criterion, optimizer, num_epochs=10):
    model.train()  # Set the model to training mode
    for epoch in range(num_epochs):
        for inputs, labels in train_loader:
            optimizer.zero_grad()  # Clear previous gradients
            outputs = model(inputs)  # Forward pass
            loss = criterion(outputs, labels)  # Calculate loss
            loss.backward()  # Backward pass to calculate gradients
            optimizer.step()  # Update model parameters
            
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')  # Print loss for each epoch

# Step 5: Initialize and Train the Model
num_classes = 2  # Update based on your number of classes (real, fake)
model = SimpleCNN(num_classes)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

train_model(model, train_loader, criterion, optimizer)

# Step 6: Evaluate the Models
def evaluate_model(model, test_loader):
    model.eval()  # Set the model to evaluation mode
    total = 0  # Initialize total count
    correct = 0  # Initialize correct prediction count
    with torch.no_grad():  # Disable gradient calculation for evaluation
        for inputs, labels in test_loader:
            outputs = model(inputs)  # Get model predictions
            _, predicted = torch.max(outputs.data, 1)  # Get the predicted class
            total += labels.size(0)  # Update total count
            correct += (predicted == labels).sum().item()  # Count correct predictions

    print(f'Accuracy of the model on test videos: {100 * correct / total:.2f}%')

# Call the evaluation function for both models
evaluate_model(model, test_loader)  # Evaluate the CNN model
